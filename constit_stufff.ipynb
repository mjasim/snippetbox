{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "\n",
    "with open(\"gists/minidogs.jsonl\", \"r\") as inf:\n",
    "    lns = [json.loads(i) for i in inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'ROOT'\n",
    "def getNodes(parent, out):\n",
    "    for node in parent:\n",
    "        if type(node) is nltk.Tree:\n",
    "            if node.label() == ROOT:\n",
    "                print(\"======== Sentence =========\")\n",
    "                print(\"Sentence:\", \" \".join(node.leaves()))\n",
    "            else:\n",
    "                #print(\"Label:\", node.label())\n",
    "                #print(\"Leaves:\", node.leaves())\n",
    "                if len(node.leaves()) > 1:\n",
    "                    out.append((node.label(), \" \".join(node.leaves())))\n",
    "\n",
    "            getNodes(node, out)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments.envs import ENVIRONMENTS\n",
    "import argparse\n",
    "import kenlm\n",
    "import json\n",
    "\n",
    "from klm.query import LM\n",
    "from klm.query import get_unigram_probs\n",
    "\n",
    "env = ENVIRONMENTS[\"DEV\"]\n",
    "LOC = env['klm_model']\n",
    "UG_MODEL = env[\"ug_model\"]\n",
    "\n",
    "lm = LM(loc=LOC)\n",
    "up = get_unigram_probs(UG_MODEL)\n",
    "from klm.query import slor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VP', 150),\n",
       " ('S', 150),\n",
       " ('NP', 141),\n",
       " ('PP', 105),\n",
       " ('SBAR', 70),\n",
       " ('ADJP', 43),\n",
       " ('ADVP', 18),\n",
       " ('FRAG', 17),\n",
       " ('PRN', 13),\n",
       " ('SQ', 7),\n",
       " ('UCP', 6),\n",
       " ('SBARQ', 3),\n",
       " ('WHNP', 3),\n",
       " ('QP', 2),\n",
       " ('INTJ', 2),\n",
       " ('NP-TMP', 2),\n",
       " ('LST', 1),\n",
       " ('SINV', 1),\n",
       " ('WHPP', 1)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tree import *\n",
    "from collections import defaultdict\n",
    "\n",
    "label2slor = defaultdict(list)\n",
    "\n",
    "constit_dfs = []\n",
    "\n",
    "for l in lns:\n",
    "    out = list()\n",
    "    tree2 = Tree.fromstring(l[\"parse\"])\n",
    "    getNodes(tree2, out)\n",
    "    slabels = set()\n",
    "    for o in out:\n",
    "        label, str_ = o\n",
    "        slabels.add(label)\n",
    "        label2slor[label].append(slor(str_,lm, up))\n",
    "    for s in slabels:\n",
    "        constit_dfs.append(s)\n",
    "        \n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "l2nlor = [(l, np.mean(label2slor[l])) for l in label2slor]\n",
    "l2nlor.sort(key=lambda x:x[1], reverse=True)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "constits = [o for o in Counter(constit_dfs).most_common()]\n",
    "constits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('thirty min walks a day .', 0.9980161390218095)\n",
      "('My little couch potato dog needs', 0.6113157377929687)\n",
      "('3 thirty min walks a day', 0.4164939557576499)\n",
      "('little couch potato dog needs 3', 0.3197258045450842)\n",
      "('couch potato dog needs 3 thirty', 0.031799057637532734)\n",
      "('potato dog needs 3 thirty min', 0.03132666356608086)\n",
      "('dog needs 3 thirty min walks', 0)\n",
      "('needs 3 thirty min walks a', 0)\n"
     ]
    }
   ],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])\n",
    "\n",
    "index = 26\n",
    "all_ = []\n",
    "for o in find_ngrams([o[\"word\"] for o in lns[index]['tokens']], n=6):\n",
    "    str_ = \" \".join(o)\n",
    "    all_.append((str_, max(slor(str_,lm, up), 0)))\n",
    "    \n",
    "all_.sort(key=lambda x:x[1], reverse=True)\n",
    "\n",
    "for o in all_:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(' my little couch potato needs 3 thirty minute ... ', 0.6129066852813718)\n",
      "(' my little couch potato ...  3 thirty minute walks', 0.5386765264556885)\n",
      "(' my little couch potato needs ...  thirty minute walks', 0.5155214225158691)\n",
      "(' my little couch potato needs 3 ...  minute walks', 0.3912193690338137)\n",
      "(' my ...  couch potato needs 3 thirty minute walks', 0.3645562493133543)\n",
      "(' my little couch potato needs 3 thirty ...  walks', 0.3547105074310304)\n",
      "(' my little couch ...  needs 3 thirty minute walks', 0.3040491313323983)\n",
      "(' ...  little couch potato needs 3 thirty minute walks', 0.30112789797973605)\n",
      "(' my little ...  potato needs 3 thirty minute walks', 0.19168549163208048)\n",
      "7\n",
      "(' my little couch potato ...  thirty minute walks', 0.6974210636648996)\n",
      "(' my little couch potato needs 3 ...  walks', 0.5883220816476005)\n",
      "(' my little couch potato needs 3 thirty ... ', 0.37479685377022876)\n",
      "(' my little couch potato needs ...  minute walks', 0.308935251831055)\n",
      "(' ...  couch potato needs 3 thirty minute walks', 0.25427367890276287)\n",
      "(' my little ...  needs 3 thirty minute walks', 0.17288657604282978)\n",
      "(' my little couch ...  3 thirty minute walks', 0.16704978550153474)\n",
      "(' my ...  potato needs 3 thirty minute walks', -0.043912139010183794)\n",
      "6\n",
      "(' my little couch potato needs 3 ... ', 0.6203378686035155)\n",
      "(' my little couch potato ...  minute walks', 0.4867204713907884)\n",
      "(' my little couch potato needs ...  walks', 0.43188343225097664)\n",
      "(' my little couch ...  thirty minute walks', 0.2903142733113609)\n",
      "(' my little ...  3 thirty minute walks', 0.11115881541748014)\n",
      "(' my ...  needs 3 thirty minute walks', 0.014212933605957545)\n",
      "(' ...  potato needs 3 thirty minute walks', -0.2821087892944334)\n",
      "5\n",
      "(' my little couch potato ...  walks', 0.669815331806641)\n",
      "(' my little couch potato needs ... ', 0.6485357496240234)\n",
      "(' my little ...  thirty minute walks', 0.24789762530273407)\n",
      "(' my ...  3 thirty minute walks', -0.04047663839355451)\n",
      "(' my little couch ...  minute walks', -0.04394817695800697)\n",
      "(' ...  needs 3 thirty minute walks', -0.3931149450537106)\n",
      "4\n",
      "(' my little couch potato ... ', 1.1143123881042483)\n",
      "(' my little couch ...  walks', 0.05225323647461)\n",
      "(' my little ...  minute walks', -0.043046234362792646)\n",
      "(' my ...  thirty minute walks', -0.18130813893432585)\n",
      "(' ...  3 thirty minute walks', -0.29982964692993175)\n",
      "3\n",
      "(' my little couch ... ', 0.25370453472493537)\n",
      "(' ...  thirty minute walks', 0.13895671148274738)\n",
      "(' my little ...  walks', -0.09779422003580744)\n",
      "(' my ...  minute walks', -0.8956190576822914)\n",
      "2\n",
      "(' my little ... ', -0.32163596932983385)\n",
      "(' my ...  walks', -0.4901304103454587)\n",
      "(' ...  minute walks', -1.6587574370483402)\n",
      "1\n",
      "(' my ... ', -2.5004181580200195)\n",
      "(' ...  walks', -2.6481871603515623)\n",
      "0\n",
      "(' ... ', 5.1463767799835205)\n"
     ]
    }
   ],
   "source": [
    "toks = \"my little couch potato needs 3 thirty minute walks\".split()\n",
    "\n",
    "def insert_all_ellipses(toks, start_index, end_index):\n",
    "    '''\n",
    "    return all spans of toks with elipeses removed\n",
    "    \n",
    "    This is quadratic b/c you loop over start and ends of elipses. This cuts\n",
    "    down on the search complexity of the problem\n",
    "    \n",
    "    start_index(int): where to start looping, to insert ellipse\n",
    "    end_index(int): where to end looping, to insert ellipse\n",
    "         - If you are looping over the whole sentences then \n",
    "             - start_index = 0 and end_index = len(toks)\n",
    "         - But also you might loop over the last 5 tokens in the sentence\n",
    "         \n",
    "    You could make more recursive calls to add more ellipses\n",
    "    \n",
    "    Returns a list of tuples. \n",
    "        - The first item in the tuple is the tokens included \n",
    "        - The second item in the tuple is the start of ellipse\n",
    "        - The third item in the tuple is the end of ellipse\n",
    "    '''\n",
    "    for start_ellipse in range(start_index, end_index):\n",
    "        for end_ellipse in range(start_ellipse + 1, end_index):\n",
    "            yield(start_ellipse, end_ellipse)\n",
    "    \n",
    "opts = []\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "classes = defaultdict(list)\n",
    "\n",
    "for i in insert_all_ellipses(toks, start_index=0, end_index=len(toks) + 1):\n",
    "    ellipse_min, ellipse_max = i\n",
    "    printthis = \"\"\n",
    "    for tno, t in enumerate(toks):\n",
    "        if tno == ellipse_min:\n",
    "            printthis = printthis + \" ... \"\n",
    "        elif tno > ellipse_min and tno < ellipse_max:\n",
    "            pass\n",
    "        else:\n",
    "            printthis = printthis + \" \" + t\n",
    "    str_ = printthis.replace(\" ... \", \" \").strip().replace(\"  \", \" \")\n",
    "    classes[len(str_.split())].append((printthis, slor(str_,lm, up)))\n",
    "    \n",
    "for c in classes:\n",
    "    print(\"{}\".format(c))\n",
    "    opts = classes[c]\n",
    "    opts.sort(key=lambda x:x[1], reverse=True)\n",
    "    opts[0:20]\n",
    "    for o in opts:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('my', -3.6942735),\n",
       " ('little', -3.8233995),\n",
       " ('couch', -4.7277107),\n",
       " ('potato', -4.621139),\n",
       " ('needs', -3.7470686),\n",
       " ('walks', -4.2313447)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slor(\"my little couch potato thirty minute walks\",lm, up)\n",
    "lm.model.score(\"my little couch potato needs walks\", bos = True, eos = True)\n",
    "\n",
    "\n",
    "[(u, up[u]) for u in \"my little couch potato needs walks\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My little couch potato dog needs 3 thirty min walks a day .\n",
      "('My little couch potato dog needs 3 thirty min walks a day .', 0.8180272019343447)\n",
      "('My little couch potato dog needs 3 thirty min', 0.7242806523708762)\n",
      "('My little couch potato dog', 0.6557964061962892)\n",
      "('walks a day', 0.09627045926513667)\n",
      "('3 thirty min', 0.08536011938476544)\n",
      "('a day', -0.09840599101257297)\n",
      "('needs 3 thirty min', -0.1275434680114751)\n",
      "('3 thirty', -1.6068268827514647)\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "opts = []\n",
    "K = 20\n",
    "sno = 26\n",
    "tree2 = Tree.fromstring(lns[sno][\"parse\"])\n",
    "getNodes(tree2, out)\n",
    "for o in out:\n",
    "    label, frag = o\n",
    "    if len(frag.split()) < K:\n",
    "        opts.append((frag, slor(frag,lm, up)))\n",
    "\n",
    "opts = list(set(opts))\n",
    "opts.sort(key=lambda x:x[1],reverse=True)\n",
    "\n",
    "print(\" \".join([o[\"word\"] for o in lns[sno][\"tokens\"]]))\n",
    "for o in opts:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S',\n",
       "  \"`` The first thing I thought was ` shes in heat ' , but since that 's not it ... check and see if her vulva looks red or swollen or any discharge , I had a male that was doing that to a female and it was because she had a yeast infection .\"),\n",
       " ('S',\n",
       "  \"The first thing I thought was ` shes in heat ' , but since that 's not it ... check and see if her vulva looks red or swollen or any discharge , I had a male that was doing that to a female\"),\n",
       " ('NP',\n",
       "  \"The first thing I thought was ` shes in heat ' , but since that 's not it ... check and see if her vulva looks red or swollen or any discharge\"),\n",
       " ('NP', 'The first thing'),\n",
       " ('SBAR',\n",
       "  \"I thought was ` shes in heat ' , but since that 's not it ... check and see if her vulva looks red or swollen or any discharge\"),\n",
       " ('S',\n",
       "  \"I thought was ` shes in heat ' , but since that 's not it ... check and see if her vulva looks red or swollen or any discharge\"),\n",
       " ('VP',\n",
       "  \"thought was ` shes in heat ' , but since that 's not it ... check and see if her vulva looks red or swollen or any discharge\"),\n",
       " ('SBAR', \"was ` shes in heat ' , but since that 's not it\"),\n",
       " ('SBAR', \"was ` shes in heat '\"),\n",
       " ('S', \"was ` shes in heat '\"),\n",
       " ('VP', \"was ` shes in heat '\"),\n",
       " ('NP', \"` shes in heat '\"),\n",
       " ('PP', 'in heat'),\n",
       " ('SBAR', \"since that 's not it\"),\n",
       " ('S', \"that 's not it\"),\n",
       " ('VP', \"'s not it\"),\n",
       " ('NP', 'check and see if her vulva looks red or swollen or any discharge'),\n",
       " ('NP', 'check and see if her vulva looks red'),\n",
       " ('S', 'see if her vulva looks red'),\n",
       " ('VP', 'see if her vulva looks red'),\n",
       " ('SBAR', 'if her vulva looks red'),\n",
       " ('S', 'her vulva looks red'),\n",
       " ('NP', 'her vulva'),\n",
       " ('VP', 'looks red'),\n",
       " ('NP', 'swollen or any discharge'),\n",
       " ('NP', 'any discharge'),\n",
       " ('VP', 'had a male that was doing that to a female'),\n",
       " ('NP', 'a male that was doing that to a female'),\n",
       " ('NP', 'a male'),\n",
       " ('SBAR', 'that was doing that to a female'),\n",
       " ('S', 'was doing that to a female'),\n",
       " ('VP', 'was doing that to a female'),\n",
       " ('VP', 'doing that to a female'),\n",
       " ('PP', 'to a female'),\n",
       " ('NP', 'a female'),\n",
       " ('S', 'it was because she had a yeast infection'),\n",
       " ('VP', 'was because she had a yeast infection'),\n",
       " ('SBAR', 'because she had a yeast infection'),\n",
       " ('S', 'she had a yeast infection'),\n",
       " ('VP', 'had a yeast infection'),\n",
       " ('NP', 'a yeast infection')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sno = 17\n",
    "\n",
    "out = list()\n",
    "tree2 = Tree.fromstring(lns[sno][\"parse\"])\n",
    "getNodes(tree2, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('was because she had a yeast infection',\n",
       "  'because she had a yeast infection',\n",
       "  'she had a yeast infection'),\n",
       " ('was because she had a yeast infection',\n",
       "  'because she had a yeast infection',\n",
       "  'had a yeast infection'),\n",
       " ('was because she had a yeast infection',\n",
       "  'because she had a yeast infection',\n",
       "  'a yeast infection'),\n",
       " ('was because she had a yeast infection',\n",
       "  'she had a yeast infection',\n",
       "  'had a yeast infection'),\n",
       " ('was because she had a yeast infection',\n",
       "  'she had a yeast infection',\n",
       "  'a yeast infection'),\n",
       " ('was because she had a yeast infection',\n",
       "  'had a yeast infection',\n",
       "  'a yeast infection'),\n",
       " ('because she had a yeast infection',\n",
       "  'she had a yeast infection',\n",
       "  'had a yeast infection'),\n",
       " ('because she had a yeast infection',\n",
       "  'she had a yeast infection',\n",
       "  'a yeast infection'),\n",
       " ('because she had a yeast infection',\n",
       "  'had a yeast infection',\n",
       "  'a yeast infection'),\n",
       " ('she had a yeast infection', 'had a yeast infection', 'a yeast infection')]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm = [p[1] for p in out]\n",
    "import itertools\n",
    "co = 0\n",
    "opts = []\n",
    "max_c = 100\n",
    "\n",
    "for i in range(1,4):\n",
    "    for v in itertools.combinations(tm, r=i):\n",
    "        co += 1\n",
    "        if sum([len(i) for i in v]) < max_c:\n",
    "            opts.append(v)\n",
    "    \n",
    "opts[-10:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
