{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import itertools\n",
    "import argparse\n",
    "from klm.query import slor, LM, get_unigram_probs\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "with open(\"gists/minidogs.jsonl\", \"r\") as inf:\n",
    "    lns = [json.loads(i) for i in inf]\n",
    "    \n",
    "from environments.envs import ENVIRONMENTS\n",
    "\n",
    "env = ENVIRONMENTS[\"DEV\"]\n",
    "LOC = env['klm_model']\n",
    "UG_MODEL = env[\"ug_model\"]\n",
    "\n",
    "lm = LM(loc=LOC)\n",
    "up = get_unigram_probs(UG_MODEL)\n",
    "\n",
    "ROOT = 'ROOT'\n",
    "\n",
    "\n",
    "def get_all_combos_of_constituents(jdoc, max_c=100, p=.75):\n",
    "    '''\n",
    "    If you assume that the linguistic units are constituents and assume that you want to fill at least \n",
    "    p percent of your budget and that you want no more than K elllipses... this is actually combinatorily\n",
    "    tractable FOR A SINGLE SENTENCE\n",
    "    \n",
    "    You just want all nCk combos of constituents, for 1 .... K + 1.\n",
    "    \n",
    "    - Then you exclude all of the combos w len more than b and less than p * b\n",
    "    - You also exclude cases where one unit is nested in the other. You can exclued these safely I think b/c\n",
    "      if there is a set (x1, x2... xn) s.t xi \\in xj then there will be \n",
    "      another set (x1, x2... xn) that includes all but xi that makes better use of the xi position\n",
    "    '''\n",
    " \n",
    "    out = list()\n",
    "    tree2 = Tree.fromstring(jdoc[\"parse\"])\n",
    "    getNodes(tree2, out)\n",
    "\n",
    "    tm = [p[1] for p in out]\n",
    "\n",
    "    co = 0\n",
    "    opts = list()\n",
    "    def has_overlap(tm):\n",
    "        for a,b in itertools.combinations(tm, r=2):\n",
    "            if a in b or b in a:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    for i in range(1,4):\n",
    "        for v in itertools.combinations(tm, r=i):\n",
    "            co += 1\n",
    "            if sum([len(i) for i in v]) < max_c and sum([len(i) for i in v]) > (p * max_c):\n",
    "                if not has_overlap(v):\n",
    "                    opts.append(list(v))\n",
    "    return opts\n",
    "\n",
    "\n",
    "def combo2snippet(jdoc,combos):\n",
    "    sent = \" \".join([o[\"word\"] for o in jdoc[\"tokens\"]])\n",
    "    combos.sort(key=lambda x:sent.index(x))\n",
    "    return(\"...\".join([c for c in combos]))\n",
    "\n",
    "\n",
    "def getNodes(parent, out):\n",
    "    for node in parent:\n",
    "        if type(node) is nltk.Tree:\n",
    "            if node.label() == ROOT:\n",
    "                print(\"======== Sentence =========\")\n",
    "                print(\"Sentence:\", \" \".join(node.leaves()))\n",
    "            else:\n",
    "                if len(node.leaves()) > 1:\n",
    "                    out.append((node.label(), \" \".join(node.leaves())))\n",
    "\n",
    "            getNodes(node, out)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "\n",
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])\n",
    "\n",
    "\n",
    "def insert_all_ellipses(toks, start_index, end_index):\n",
    "    '''\n",
    "    \n",
    "    here is another thing that does not really work. \n",
    "    \n",
    "    assume you have  sequence of tokens. Now you want to insert an elipse somewhere. This returns all of the \n",
    "    places where you can get an ellipse. \n",
    "    \n",
    "    This is quadratic b/c you loop over start and ends of elipses. This cuts\n",
    "    down on the search complexity of compressive summarization problem\n",
    "    \n",
    "    If you made K recursive calls to add more ellipses, I bet you'd find that high ranking cases mapped to constituents, kind of.\n",
    "    \n",
    "    This is something we could use to justify the constituent assumption tho\n",
    "    \n",
    "    More details: \n",
    "\n",
    "    start_index(int): where to start looping, to insert ellipse\n",
    "    end_index(int): where to end looping, to insert ellipse\n",
    "         - If you are looping over the whole sentences then \n",
    "             - start_index = 0 and end_index = len(toks)\n",
    "         - But also you might loop over the last 5 tokens in the sentence\n",
    "    \n",
    "    Returns a list of tuples. \n",
    "        - The first item in the tuple is the tokens included \n",
    "        - The second item in the tuple is the start of ellipse\n",
    "        - The third item in the tuple is the end of ellipse\n",
    "    '''\n",
    "    for start_ellipse in range(start_index, end_index):\n",
    "        for end_ellipse in range(start_ellipse + 1, end_index):\n",
    "            yield(start_ellipse, end_ellipse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does SLOR do a good job finding well-formed ngrams? \n",
    "No. Sort of disappointed. I guess the coarse ranking is good but fine-grained is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('thirty min walks a day .', 0.9980161390218095)\n",
      "('My little couch potato dog needs', 0.6113157377929687)\n",
      "('3 thirty min walks a day', 0.4164939557576499)\n",
      "('little couch potato dog needs 3', 0.3197258045450842)\n",
      "('couch potato dog needs 3 thirty', 0.031799057637532734)\n",
      "('potato dog needs 3 thirty min', 0.03132666356608086)\n",
      "('dog needs 3 thirty min walks', 0)\n",
      "('needs 3 thirty min walks a', 0)\n"
     ]
    }
   ],
   "source": [
    "index = 26\n",
    "all_ = []\n",
    "for o in find_ngrams([o[\"word\"] for o in lns[index]['tokens']], n=6):\n",
    "    str_ = \" \".join(o)\n",
    "    all_.append((str_, max(slor(str_,lm, up), 0)))\n",
    "    \n",
    "all_.sort(key=lambda x:x[1], reverse=True)\n",
    "\n",
    "for o in all_:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does SLOR do a good job finding well-formed constituents? \n",
    "- No. Sort of disappointed. The coarse ranking is good but not the fine-grained ranking, basically. This fits w/ Lau Clarke Lapin who found an approximate correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My little couch potato dog needs 3 thirty min walks a day .\n",
      "('My little couch potato dog needs 3 thirty min walks a day .', 0.8180272019343447)\n",
      "('My little couch potato dog needs 3 thirty min', 0.7242806523708762)\n",
      "('My little couch potato dog', 0.6557964061962892)\n",
      "('walks a day', 0.09627045926513667)\n",
      "('3 thirty min', 0.08536011938476544)\n",
      "('a day', -0.09840599101257297)\n",
      "('needs 3 thirty min', -0.1275434680114751)\n",
      "('3 thirty', -1.6068268827514647)\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "opts = []\n",
    "K = 20\n",
    "sno = 26\n",
    "tree2 = Tree.fromstring(lns[sno][\"parse\"])\n",
    "getNodes(tree2, out)\n",
    "for o in out:\n",
    "    label, frag = o\n",
    "    if len(frag.split()) < K:\n",
    "        opts.append((frag, slor(frag,lm, up)))\n",
    "\n",
    "opts = list(set(opts))\n",
    "opts.sort(key=lambda x:x[1],reverse=True)\n",
    "\n",
    "print(\" \".join([o[\"word\"] for o in lns[sno][\"tokens\"]]))\n",
    "for o in opts:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A method that works\n",
    "\n",
    "Assume you want only a few ellipses (2/3) per sentence. Assume you want to fill your summary budget up to 75%. You can really just enumerate all combos of constituents of size 1,2,3,4, and filter out those that are too long and too short. This is because the number of ellipses will in general be size of combo + 1. There are a manageable number of subsets to just check. If we rank the resullting snippets by SLOR, imagining that the ... are not present, well everything seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 snippets, by SLOR\n",
      "(\"we would like to have two dogs eventually...you ca n't have one in the bed and one in the crate\", 1.4404289123767673)\n",
      "(\"we would like to have two dogs eventually...ca n't have one in the bed and one in the crate\", 1.42768482941162)\n",
      "(\"because we would like to have two dogs eventually...ca n't have one in the bed and one in the crate\", 1.336877888411458)\n",
      "(\"as well because we would like to have two dogs eventually...you 're right...in the crate\", 1.3338324352366726)\n",
      "(\"to have two dogs eventually...you 're right...you ca n't have one in the bed and one in the crate\", 1.3122329012765062)\n",
      "(\"to have two dogs eventually...you 're right...you ca n't have one in the bed and one in the crate\", 1.3122329012765062)\n",
      "(\"my SO...we would like to have two dogs eventually...you ca n't have one in the bed and one in the crate\", 1.2662316655910322)\n",
      "(\"like to have two dogs eventually...you 're right...you ca n't have one in the bed and one in the crate\", 1.2614249192693534)\n",
      "(\"to have two dogs eventually...you ca n't have one in the bed and one in the crate\", 1.2571505000515397)\n",
      "(\"to have two dogs eventually...you ca n't have one in the bed and one in the crate\", 1.2571505000515397)\n",
      "\n",
      "\n",
      "bottom 10 snippets, by SLOR\n",
      "('yeah my SO...a king sized bed as well because we would like to have two dogs eventually', 0.5580380523301867)\n",
      "('yeah my SO...a king sized bed as well because we would like to have two dogs eventually', 0.5580380523301867)\n",
      "('yeah my SO...a king...sized bed as well because we would like to have two dogs eventually', 0.5580380523301867)\n",
      "('yeah my SO...a king sized bed as well because we would like to have two dogs eventually...the bed', 0.547011414575195)\n",
      "('yeah my SO...a king sized bed as well because we would like to have two dogs eventually...the bed', 0.547011414575195)\n",
      "(\"yeah my SO...sized bed as well because we would like to have two dogs eventually...'re right\", 0.5455466749321837)\n",
      "(\"Haha yeah my SO...a king sized bed as well because we would like to have two dogs eventually...'re right\", 0.5146996997302831)\n",
      "(\"Haha yeah my SO...a king sized bed as well because we would like to have two dogs eventually...'re right\", 0.5146996997302831)\n",
      "(\"yeah my SO...a king sized bed as well because we would like to have two dogs eventually...'re right\", 0.48493399003906246)\n",
      "(\"yeah my SO...a king sized bed as well because we would like to have two dogs eventually...'re right\", 0.48493399003906246)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sno = 35\n",
    "combos = get_all_combos_of_constituents(lns[sno])\n",
    "\n",
    "ranks = []\n",
    "\n",
    "for c in combos:\n",
    "    snip = combo2snippet(lns[sno], c)\n",
    "    \n",
    "    ranks.append((snip, slor(snip.replace(\"...\", \" \").replace(\"  \", \" \"),lm, up)))\n",
    "    \n",
    "ranks.sort(key=lambda x:x[1], reverse=True)\n",
    "\n",
    "print(\"top 10 snippets, by SLOR\")\n",
    "for r in ranks[0:10]:\n",
    "    print(r)\n",
    "print(\"\\n\")\n",
    "print(\"bottom 10 snippets, by SLOR\")\n",
    "for r in ranks[-10:]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(' my little couch potato needs 3 thirty minute ... ', 0.6129066852813718)\n",
      "(' my little couch potato ...  3 thirty minute walks', 0.5386765264556885)\n",
      "(' my little couch potato needs ...  thirty minute walks', 0.5155214225158691)\n",
      "(' my little couch potato needs 3 ...  minute walks', 0.3912193690338137)\n",
      "(' my ...  couch potato needs 3 thirty minute walks', 0.3645562493133543)\n",
      "(' my little couch potato needs 3 thirty ...  walks', 0.3547105074310304)\n",
      "(' my little couch ...  needs 3 thirty minute walks', 0.3040491313323983)\n",
      "(' ...  little couch potato needs 3 thirty minute walks', 0.30112789797973605)\n",
      "(' my little ...  potato needs 3 thirty minute walks', 0.19168549163208048)\n",
      "7\n",
      "(' my little couch potato ...  thirty minute walks', 0.6974210636648996)\n",
      "(' my little couch potato needs 3 ...  walks', 0.5883220816476005)\n",
      "(' my little couch potato needs 3 thirty ... ', 0.37479685377022876)\n",
      "(' my little couch potato needs ...  minute walks', 0.308935251831055)\n",
      "(' ...  couch potato needs 3 thirty minute walks', 0.25427367890276287)\n",
      "(' my little ...  needs 3 thirty minute walks', 0.17288657604282978)\n",
      "(' my little couch ...  3 thirty minute walks', 0.16704978550153474)\n",
      "(' my ...  potato needs 3 thirty minute walks', -0.043912139010183794)\n",
      "6\n",
      "(' my little couch potato needs 3 ... ', 0.6203378686035155)\n",
      "(' my little couch potato ...  minute walks', 0.4867204713907884)\n",
      "(' my little couch potato needs ...  walks', 0.43188343225097664)\n",
      "(' my little couch ...  thirty minute walks', 0.2903142733113609)\n",
      "(' my little ...  3 thirty minute walks', 0.11115881541748014)\n",
      "(' my ...  needs 3 thirty minute walks', 0.014212933605957545)\n",
      "(' ...  potato needs 3 thirty minute walks', -0.2821087892944334)\n",
      "5\n",
      "(' my little couch potato ...  walks', 0.669815331806641)\n",
      "(' my little couch potato needs ... ', 0.6485357496240234)\n",
      "(' my little ...  thirty minute walks', 0.24789762530273407)\n",
      "(' my ...  3 thirty minute walks', -0.04047663839355451)\n",
      "(' my little couch ...  minute walks', -0.04394817695800697)\n",
      "(' ...  needs 3 thirty minute walks', -0.3931149450537106)\n",
      "4\n",
      "(' my little couch potato ... ', 1.1143123881042483)\n",
      "(' my little couch ...  walks', 0.05225323647461)\n",
      "(' my little ...  minute walks', -0.043046234362792646)\n",
      "(' my ...  thirty minute walks', -0.18130813893432585)\n",
      "(' ...  3 thirty minute walks', -0.29982964692993175)\n",
      "3\n",
      "(' my little couch ... ', 0.25370453472493537)\n",
      "(' ...  thirty minute walks', 0.13895671148274738)\n",
      "(' my little ...  walks', -0.09779422003580744)\n",
      "(' my ...  minute walks', -0.8956190576822914)\n",
      "2\n",
      "(' my little ... ', -0.32163596932983385)\n",
      "(' my ...  walks', -0.4901304103454587)\n",
      "(' ...  minute walks', -1.6587574370483402)\n",
      "1\n",
      "(' my ... ', -2.5004181580200195)\n",
      "(' ...  walks', -2.6481871603515623)\n",
      "0\n",
      "(' ... ', 5.1463767799835205)\n"
     ]
    }
   ],
   "source": [
    "from environments.envs import ENVIRONMENTS\n",
    "import argparse\n",
    "import kenlm\n",
    "import json\n",
    "\n",
    "from klm.query import LM\n",
    "from klm.query import get_unigram_probs\n",
    "\n",
    "env = ENVIRONMENTS[\"DEV\"]\n",
    "LOC = env['klm_model']\n",
    "UG_MODEL = env[\"ug_model\"]\n",
    "\n",
    "lm = LM(loc=LOC)\n",
    "up = get_unigram_probs(UG_MODEL)\n",
    "from klm.query import slor\n",
    "\n",
    "\n",
    "toks = \"my little couch potato needs 3 thirty minute walks\".split()\n",
    "\n",
    "opts = []\n",
    "\n",
    "classes = defaultdict(list)\n",
    "\n",
    "for i in insert_all_ellipses(toks, start_index=0, end_index=len(toks) + 1):\n",
    "    ellipse_min, ellipse_max = i\n",
    "    printthis = \"\"\n",
    "    for tno, t in enumerate(toks):\n",
    "        if tno == ellipse_min:\n",
    "            printthis = printthis + \" ... \"\n",
    "        elif tno > ellipse_min and tno < ellipse_max:\n",
    "            pass\n",
    "        else:\n",
    "            printthis = printthis + \" \" + t\n",
    "    str_ = printthis.replace(\" ... \", \" \").strip().replace(\"  \", \" \")\n",
    "    classes[len(str_.split())].append((printthis, slor(str_,lm, up)))\n",
    "    \n",
    "for c in classes:\n",
    "    print(c)\n",
    "    opts = classes[c]\n",
    "    opts.sort(key=lambda x:x[1], reverse=True)\n",
    "    opts[0:20]\n",
    "    for o in opts:\n",
    "        print(o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
